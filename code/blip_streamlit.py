import streamlit as st
import os
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration
import torch
from openai import OpenAI
import dotenv
import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
today = datetime.date.today()
weekday = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
formatted_date = f"{today.year}ë…„ {today.month}ì›” {today.day}ì¼, {weekday[today.weekday()]}"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì‚¬ì§„ ì¼ê¸° ìƒì„±ê¸°", layout="wide")
st.title("AI ì‚¬ì§„ ì¼ê¸° ìƒì„±ê¸°")

# BLIP ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_models():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
    model = Blip2ForConditionalGeneration.from_pretrained(
        "Salesforce/blip2-opt-2.7b", 
        load_in_8bit=True, 
        device_map={"": 0}, 
        torch_dtype=torch.float16
    )
    return device, processor, model

device, processor, model = load_models()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=OPENAI_API_KEY)

# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
st.header("ì‚¬ì§„ ì—…ë¡œë“œ")
uploaded_files = st.file_uploader("ì—¬ëŸ¬ ì¥ì˜ ì‚¬ì§„ì„ ì„ íƒí•˜ì„¸ìš”", type=['jpg', 'jpeg', 'png'], accept_multiple_files=True)

if uploaded_files:
    captions_with_info = []
    
    for uploaded_file in uploaded_files:
        st.subheader(f"ì‚¬ì§„: {uploaded_file.name}")
        
        # ì´ë¯¸ì§€ì™€ ì…ë ¥ í•„ë“œë¥¼ ë‚˜ë€íˆ ë°°ì¹˜
        col1, col2 = st.columns([1, 2])  # 1:2 ë¹„ìœ¨ë¡œ ì»¬ëŸ¼ ë¶„í• 
        
        with col1:
            # ì´ë¯¸ì§€ í‘œì‹œ
            image = Image.open(uploaded_file)
            # PIL ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
            image = image.convert('RGB')
            st.image(image, caption=uploaded_file.name, width=200)
        
        with col2:
            # BLIP ìº¡ì…˜ ìƒì„±
            inputs = processor(images=image, return_tensors="pt").to(device, torch.float16)
            generated_ids = model.generate(**inputs)
            generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
            
            st.write(f"BLIP ìº¡ì…˜: {generated_text}")
            
            # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
            person_name = st.text_input(f"ì‚¬ì§„ ì† ë‹¤ë¥¸ ì¸ë¬¼ë“¤ì˜ ì´ë¦„", key=f"person_{uploaded_file.name}")
            location = st.text_input(f"ì´¬ì˜ ì¥ì†Œ", key=f"location_{uploaded_file.name}")
            keywords = st.text_input(f"í™œë™ í‚¤ì›Œë“œ",
                                  key=f"keywords_{uploaded_file.name}")
        
        # ì •ë³´ ì €ì¥
        caption_info = {
            'image': uploaded_file.name,
            'caption': generated_text,
            'person': person_name if person_name else "",
            'location': location if location else "ì–´ë”˜ê°€",
            'keywords': keywords if keywords else ""
        }
        captions_with_info.append(caption_info)
        
        # êµ¬ë¶„ì„  ì¶”ê°€
        st.divider()
    
    # ì¼ê¸° ë¶„ìœ„ê¸° ì§ì ‘ ì…ë ¥
    mood = st.text_input('ì¼ê¸°ì˜ ë¶„ìœ„ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ í‰ë²”í•œ í†¤ìœ¼ë¡œ ì‘ì„±ë©ë‹ˆë‹¤)', '')

    # ì¼ê¸° ìƒì„± ë²„íŠ¼
    if st.button("ì¼ê¸° ìƒì„±í•˜ê¸°"):
        with st.spinner("AIê°€ ì¼ê¸°ë¥¼ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            diary_prompt = """ì˜¤ëŠ˜ ì°ì€ ì‚¬ì§„ë“¤ì„ ë³´ê³  ì¼ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ê° ì‚¬ì§„ì—ëŠ” AIê°€ ìƒì„±í•œ ìº¡ì…˜ê³¼ í•¨ê»˜ ì¥ì†Œ, í•¨ê»˜í•œ ì‚¬ëŒë“¤, í™œë™ í‚¤ì›Œë“œê°€ ì œê³µë©ë‹ˆë‹¤.
ì´ ì •ë³´ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•˜ì—¬ ì‹¤ì œ ìˆì—ˆë˜ ì¼ë§Œì„ ì„œìˆ í•´ì£¼ì„¸ìš”.
"""
            diary_prompt += f"ë‹¤ìŒì€ {formatted_date}ì— ìˆì—ˆë˜ ì¼ë“¤ì— ëŒ€í•œ ì¼ê¸°ë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•œ ì •ë³´ì…ë‹ˆë‹¤.\n\n"
            diary_prompt += "**ì…ë ¥ëœ ì‚¬ì§„ ì •ë³´** (ìˆœì„œëŒ€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”):\n"

            for i, info in enumerate(captions_with_info, 1):
                diary_prompt += f"ì‚¬ì§„ {i}\n"
                diary_prompt += f"- AI ìº¡ì…˜: {info['caption']}\n  ì¥ì†Œ: {info['location']}\n  í•¨ê»˜í•œ ì‚¬ëŒ: {info['person']}\n  í‚¤ì›Œë“œ: {info['keywords']}\n\n"

            base_guidelines = """
**ì¼ê¸° ì‘ì„± ê°€ì´ë“œë¼ì¸**:
1. **ì¼ê¸°ì˜ ì£¼ì²´ëŠ” "ë‚˜"**ì´ë©°, í•¨ê»˜í•œ ì‚¬ëŒë“¤ì„ ì ì ˆíˆ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
2. **AI ìº¡ì…˜, ì¥ì†Œ, ì¸ë¬¼, í™œë™ í‚¤ì›Œë“œë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©**í•˜ì—¬ ì‹¤ì œ ê²½í—˜ì„ ê¸°ë¡í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ í•´ì£¼ì„¸ìš”.
3. **ê°ì • í‘œí˜„ì„ ì¶”ê°€ì ìœ¼ë¡œ ë°˜ì˜**í•˜ì—¬ ì¢€ ë” ëª°ì…í•  ìˆ˜ ìˆëŠ” ê¸€ì´ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”.
4. **ì‚¬ì§„ì´ ì—…ë¡œë“œëœ ìˆœì„œë¥¼ ì‹œê°„ ìˆœì„œë¡œ ê°„ì£¼í•˜ê³ **, ì…ë ¥ëœ ìˆœì„œëŒ€ë¡œ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. (ë°¤ì— ì°ì€ ì‚¬ì§„ ë’¤ì— ë‚®ì— ì°ì€ ì‚¬ì§„ì´ ì˜¤ë©´, ë‹¤ìŒ ë‚ ë¡œ ê°„ì£¼í•´ì£¼ì„¸ìš”)
5. **ì£¼ì–´ì§„ ì •ë³´ë§Œì„ í™œìš©**í•˜ì—¬, ì¼ê¸°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            if mood.strip():  # moodê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°
                diary_prompt += base_guidelines + f'\n6. **ì…ë ¥ ë°›ì€ ë¶„ìœ„ê¸°ì— ë§ê²Œ ì¼ê¸°ë¥¼ ì‘ì„±**í•´ì£¼ì„¸ìš”. ì…ë ¥ ë°›ì€ ë¶„ìœ„ê¸°: "{mood}"'
            else:  # moodê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
                diary_prompt += base_guidelines

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ì§„ ì† ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ í•˜ëŠ” ì‘ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": diary_prompt}
                ],
                temperature=0.3,  # ì°½ì˜ì„±ì„ ë‚®ì¶°ì„œ ë” ì‚¬ì‹¤ì ì¸ ì‘ë‹µ ìœ ë„
                max_tokens=1000
            )
            
            # ê²°ê³¼ í‘œì‹œ
            st.header(f"ğŸ“… {formatted_date}")
            st.write(response.choices[0].message.content)
else:
    st.info("ìœ„ì˜ ì—…ë¡œë”ë¥¼ í†µí•´ ì‚¬ì§„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.") 